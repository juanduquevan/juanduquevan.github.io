<link rel="stylesheet"
      href="{{ '/assets/css/style.css' | relative_url }}">
<meta name="viewport" content="width=device-width, initial-scale=1">

<div class="paper">
  <img class="portrait"
         src="https://juanduquevan.github.io/docs/assets/IMG_0619.jpg" width="400" alt="Juan Duque">
  <div class="text">
    <h2><strong>Juan Duque</strong></h2>
    <p>I’m a third year PhD student in Reinforcement Learning at Université de Montréal & Mila, advised by <a href="https://scholar.google.com/citations?user=km6CP8cAAAAJ&hl=en">Aaron Courville</a>. My research unites multi agent RL, game theory, and scalable algorithms, which I apply to social dilemmas as well as climate policy simulators, large language model negotiation, and games. I enjoy turning rigorous theory into efficient algorithms that help AI systems reason and coordinate for real world impact. Before Mila, I did my master's at the <a href="https://princeton-nlp.github.io/">Princeton NLP group</a> with <a href="https://karthikncode.github.io/">Karthik Narasimhan</a> and my undergraduate at Georgia Tech where I worked with professors <a href="https://www.cc.gatech.edu/fac/Charles.Isbell/">Charles Isbell</a> and <a href="https://people.math.gatech.edu/~loss/">Michael Loss</a> in Reinforcement Learning.</p>
    <br>
    <div class="menu">
      <a href="mailto:juanduquevan@gmail.com">Email</a> / 
      <a href="https://juanduquevan.github.io/docs/assets/CV (23).pdf">CV</a> / 
      <a href="https://github.com/jduquevan">GitHub</a> / 
      <a href="https://www.linkedin.com/in/juan-duque/">LinkedIn</a>
    </div>
  </div>
</div>
<h2><strong>Publications</strong></h2>

<ul class="pub-list">

  <li class="paper-item">
    Quentin Bertrand, <strong>Juan Agustin Duque</strong>, Emilio Calvano, Gauthier Gidel.  
    <em>Q-learners Can Provably Collude in the Iterated Prisoner’s Dilemma</em>  
    <a href="https://arxiv.org/abs/2312.08484" target="_blank">[pdf]</a>  
    <span class="badge icml">ICML 2025</span>
  </li>

  <li class="paper-item">
    <strong>Juan Agustin Duque*</strong>, Milad Aghajohari*, Tim Cooijmans, Razvan Ciuca,
    Tianyu Zhang, Gauthier Gidel, Aaron Courville.  
    <em>Advantage Alignment Algorithms</em>  
    <a href="https://arxiv.org/abs/2406.14662" target="_blank">[pdf]</a>  
    <span class="badge iclr">ICLR 2025 • Oral</span>
  </li>

  <li class="paper-item">
    Milad Aghajohari*, <strong>Juan Agustin Duque*</strong>, Tim Cooijmans, Aaron Courville.  
    <em>LOQA: Learning with Opponent Q-Learning Awareness</em>  
    <a href="https://openreview.net/pdf?id=FDQF6A1s6M" target="_blank">[pdf]</a>  
    <span class="badge iclr">ICLR 2024</span>
  </li>

  <li class="paper-item">
    Milad Aghajohari, Tim Cooijmans, <strong>Juan Agustin Duque</strong>, Shunichi Akatsuka,
    Aaron Courville. <em>Best Response Shaping</em>  
    <a href="https://drive.google.com/file/d/1b2WMNDo8Mrv0r3mNx5uxOTGfxGz1FX-8/view?usp=sharing"
       target="_blank">[pdf]</a>  
    <span class="badge rlc">RLC 2024</span>
  </li>

</ul>
<br>
<br>
